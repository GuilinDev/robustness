Integrated Gradients (IG，积分梯度法)
优势：理论基础更扎实，能够为每个像素分配重要性
实现：通过captum库容易实现
处理速度：与GradCAM相当，可能更快
LIME (局部可解释的模型无关解释)
优势：模型无关，适用于任何黑盒模型
实现：通过lime库可用
处理速度：比GradCAM慢但可以并行化
SHAP (Shapley加性解释)
优势：理论基础强，结合多种归因方法
实现：通过shap库可用
处理速度：计算密集，但可以使用GradientExplainer加速
遮挡敏感度分析 (Occlusion Sensitivity)
优势：概念简单，模型无关
实现：易于从头实现
处理速度：中等，可以通过调整块大小加速
DeepLIFT
优势：比简单梯度提供更好的归因
实现：captum库提供
处理速度：通常比SHAP或LIME更快

运行顺序

SHAP (SHapley Additive exPlanations)：SHAP是基于合作博弈理论的方法，与IG和GradCAM有本质区别，能提供不同视角的解释。它的特点是可以量化每个特征对预测的贡献，有坚实的理论基础。尽管计算成本较高，但对鲁棒性研究非常有价值。
LIME (Local Interpretable Model-agnostic Explanations)：LIME通过在局部拟合可解释的线性模型来解释黑盒模型，这与梯度或特征归因方法截然不同。它是模型无关的，可以提供更直观的解释。
DeepLIFT (Deep Learning Important FeaTures)：与IG有一定相似性但计算效率更高，可以作为IG结果的补充验证。
Occlusion Sensitivity：这是一种直观的方法，通过遮挡输入图像的不同部分观察对输出的影响。实现简单但计算量大，可能需要更长时间运行。